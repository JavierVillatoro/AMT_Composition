import torch
from pathlib import Path
from miditok import REMI
from transformers import GPT2LMHeadModel
import time

# --- CONFIGURACIÃ“N ---
MODEL_PATH = Path("./model_final")       # Tu modelo entrenado
TOKENIZER_PATH = Path("./model_final")   # El tokenizer tambiÃ©n se guardÃ³ ahÃ­ al final del train
OUTPUT_DIR = Path("./generated_music")
OUTPUT_DIR.mkdir(exist_ok=True)

def generate_music():
    print("--- ðŸŽ¹ CARGANDO CEREBRO MUSICAL (INFERENCIA) ---")
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"Usando dispositivo: {device.upper()}")

    # 1. CARGAR
    try:
        # Cargamos tokenizer desde la misma carpeta del modelo
        tokenizer = REMI.from_pretrained(TOKENIZER_PATH)
        model = GPT2LMHeadModel.from_pretrained(MODEL_PATH).to(device)
        model.eval() # Modo evaluaciÃ³n (apaga el aprendizaje)
    except Exception as e:
        print(f"âŒ Error: {e}")
        print("Â¿Seguro que terminaste el entrenamiento y existe la carpeta model_final?")
        return

    print("âœ… Modelo listo. Â¡A componer!")

    while True:
        # 2. CONFIGURACIÃ“N USUARIO
        print("\n" + "-"*30)
        try:
            num_tokens = int(input("Longitud (tokens, ej. 500): ") or "500")
            temp = float(input("Temperatura (Creatividad 0.8 - 1.2): ") or "1.0")
        except:
            num_tokens, temp = 500, 1.0

        print(f"ðŸŽµ Generando obra de Chopin AI... (T={temp})")
        start_time = time.time()

        # 3. GENERACIÃ“N
        # Creamos una secuencia vacÃ­a (o con token de inicio si existe)
        # BOS = Beginning Of Sequence. Si no hay, usamos el id 0.
        bos_token = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else 0
        input_ids = torch.tensor([[bos_token]]).to(device)

        with torch.no_grad():
            generated_ids = model.generate(
                input_ids,
                max_length=num_tokens,
                do_sample=True,      # Â¡Clave! Permite variedad
                temperature=temp,    # Controla el "caos"
                top_k=50,            # Se queda con las 50 mejores opciones
                pad_token_id=tokenizer.pad_token_id,
                eos_token_id=tokenizer.pad_token_id
            )

        # 4. DECODIFICACIÃ“N (NÃºmeros -> MÃºsica)
        # Convertimos el tensor de GPU a lista de Python
        gen_seq = generated_ids[0].tolist()
        
        # CORRECCIÃ“N IMPORTANTE: Usamos .decode()
        # Esto crea un objeto Score (mÃºsica)
        midi_output = tokenizer.decode(gen_seq)
        
        # 5. GUARDAR
        timestamp = int(time.time())
        filename = OUTPUT_DIR / f"chopin_ai_{timestamp}_t{temp}.mid"
        
        # Dump midi guarda el archivo
        midi_output.dump_midi(filename)
        
        print(f"âœ¨ Â¡Terminado en {time.time() - start_time:.1f}s!")
        print(f"ðŸ’¾ Guardado en: {filename}")
        
        if input("Â¿Otra? [s/n]: ").lower() == 'n':
            break

if __name__ == "__main__":
    generate_music()