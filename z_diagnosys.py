import json
from pathlib import Path
from miditok import REMI

# --- RUTA DEL MODELO ---
TOKENIZER_PATH = Path("./model_final")  # Aseg√∫rate de que apunta a donde est√° tokenizer.json

def inspeccionar_cerebro():
    print("üïµÔ∏è‚Äç‚ôÇÔ∏è  INICIANDO DIAGN√ìSTICO PROFUNDO...")
    print(f"üìÇ Buscando tokenizer en: {TOKENIZER_PATH.absolute()}")
    
    try:
        # 1. CARGAR TOKENIZADOR
        tokenizer = REMI.from_pretrained(TOKENIZER_PATH)
        print("‚úÖ Tokenizador cargado.")
        
        # 2. PROBAR EL TOKEN MALDITO (598)
        TOKEN_MALDITO = 598
        print(f"\nüîé  ANALIZANDO TOKEN {TOKEN_MALDITO}...")
        
        # Verificamos si est√° en el vocabulario b√°sico
        vocab_size = len(tokenizer)
        print(f"   - Tama√±o del vocabulario: {vocab_size}")
        
        if TOKEN_MALDITO >= vocab_size:
            print("   üö®  ¬°ALERTA ROJA! El token 598 est√° FUERA del rango del vocabulario.")
            print("        El modelo est√° alucinando n√∫meros que no existen.")
            return

        # Intentamos obtener el evento asociado (Traducci√≥n Inversa)
        # Probamos varios m√©todos seg√∫n la versi√≥n de miditok
        event = None
        try:
            # M√©todo A: Acceso directo (versiones nuevas)
            event = tokenizer[TOKEN_MALDITO]
            print(f"   - M√©todo A (Directo): {event}")
        except:
            try:
                # M√©todo B: Vocabulario interno
                # miditok suele guardar el vocab como lista de eventos
                if hasattr(tokenizer, 'vocab') and isinstance(tokenizer.vocab, list):
                     # Buscar en la lista el valor
                     pass 
                elif hasattr(tokenizer, 'vocab') and isinstance(tokenizer.vocab, dict):
                    # Invertir diccionario
                    inv_vocab = {v: k for k, v in tokenizer.vocab.items()}
                    event = inv_vocab.get(TOKEN_MALDITO, "No encontrado")
                    print(f"   - M√©todo B (Dict): {event}")
            except Exception as e:
                print(f"   - M√©todo B fall√≥: {e}")

        # 3. INTENTO DE DECODIFICACI√ìN AISLADA
        print("\nüß™  PRUEBA DE DECODIFICACI√ìN AISLADA:")
        fake_seq = [TOKEN_MALDITO]
        try:
            # Intentamos convertir solo ese token a MIDI
            midi = tokenizer.decode(fake_seq)
            print("   ‚úÖ  ¬°INCRE√çBLE! El token se decodific√≥ correctamente solo.")
            print("        (El problema podr√≠a ser la secuencia, no el token individual)")
        except Exception as e:
            print(f"   ‚ùå  FALL√ì AL DECODIFICAR: {e}")
            print("        Este es el problema: El token existe en el vocabulario,")
            print("        pero miditok no sabe c√≥mo convertirlo a nota.")

        # 4. EXPORTAR VOCABULARIO (Para que yo lo vea)
        print("\nüìù  EXPORTANDO DICCIONARIO...")
        debug_file = "vocabulario_debug.txt"
        with open(debug_file, "w", encoding="utf-8") as f:
            if hasattr(tokenizer, "vocab") and isinstance(tokenizer.vocab, dict):
                # Ordenar por ID
                sorted_vocab = sorted(tokenizer.vocab.items(), key=lambda item: item[1])
                for k, v in sorted_vocab:
                    f.write(f"{v}: {k}\n")
            else:
                f.write("No se pudo extraer el vocabulario como diccionario simple.")
                
        print(f"   ‚úÖ Guardado en '{debug_file}'.")
        print("   -> Por favor, abre ese archivo y busca qu√© pone en la l√≠nea 598.")

    except Exception as e:
        print(f"\n‚ùå ERROR CR√çTICO EN EL DIAGN√ìSTICO: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    inspeccionar_cerebro()